{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewed/Commented by KL on 6/2/2022\n",
    "\n",
    "The American Express Default Prediction Kaggle Challenge asks participants to create a model to predict credit card defaults.  This notebook provided by a competition participant does a fantastic job of doing EDA, although with the data anonymized the amount of feature exploration will be limited.\n",
    "\n",
    "https://www.kaggle.com/code/ambrosm/amex-eda-which-makes-sense\n",
    "\n",
    "The main takeaways for the competition is that the selection criteria is a combination of ROC and Recall.\n",
    "\n",
    "Additionally, while in the training dataset of 458k customerIDs, 74% are good customers without a default, and 26% of customers are bad customers that did have a default (defined as not making a payment for 120 days in a row), the good customers were subsampled at a rate of 20.  Therefore, in reality the ratio is 98% good, to 2% bad.\n",
    "\n",
    "Further, the provided datasets is rather large, at a total of 50.31 gigs.  A few different public competition notebooks provided competitors with more efficient datasets, specifically parquat and feather.  \n",
    "\n",
    "\n",
    "### Parquat\n",
    "\n",
    "https://www.kaggle.com/competitions/amex-default-prediction/discussion/327138\n",
    "\n",
    "### Feather\n",
    "\n",
    "https://www.kaggle.com/competitions/amex-default-prediction/discussion/327143\n",
    "\n",
    "The original total dataset was 50.31 gigs.  Parquet was able to reduce it down to 10.41 gbs, and Feather was able to reduce it down to 5.4 gbs.  Additionally, the datatypes for both included reducing numeric columns to float16, and categorical to 'category' which will of course reduce data as the datatypes are more efficient.\n",
    "\n",
    "Main takeaway here is to remember that you are often given raw datasets and there is often much room for improvement, especially in file size.\n",
    "\n",
    "The dataset itself was 5.5m rows for training and 1.1m rows for test.  It appears that each row is a monthly customer statement, but without overlap in the time periods.  The test data is after the train data.  \n",
    "\n",
    "\n",
    "# Leading Competition notebooks\n",
    "\n",
    "There are 2 leading competition notebooks publically available as I write this, one based on LGBM, and one based on RNN.  The LGBM notebook is below and will have some of my comments added (denoted with a KL), and the RNN notebook will also have a link to the notebook.  I reviewed the RNN, but I will note provide a notebook with commentary in the interests of time.  \n",
    "\n",
    "### LGBM Notebook\n",
    "\n",
    "This is the one that is below.  Here, we can view the notebook fully run.\n",
    "https://www.kaggle.com/competitions/amex-default-prediction/code?competitionId=35332&sortBy=voteCount\n",
    "\n",
    "Score LB 0.792\n",
    "\n",
    "### RNN notebook\n",
    "\n",
    "https://www.kaggle.com/competitions/amex-default-prediction/discussion/327761\n",
    "\n",
    "Score LB 0.789\n",
    "\n",
    "## Comparison \n",
    "\n",
    "The RNN notebook requires signficantly more effort for data preparation.  The author of the LGBM author actually provides a great rundown of the difference between data prep for LGBM vs a NN that I will copy below:\n",
    "\n",
    "----\n",
    "Preprocessing for LightGBM is much simpler than for neural networks:\n",
    "\n",
    "Neural networks can't process missing values; LightGBM handles them automatically.\n",
    "\n",
    "Categorical features need to be one-hot encoded for neural networks; LightGBM handles them automatically.\n",
    "\n",
    "With neural networks, you need to think about outliers; tree-based algorithms deal with outliers easily.\n",
    "\n",
    "Neural networks need scaled inputs; tree-based algorithms don't depend on scaling.\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "Additionally, the LGBM actually scores a tad better than the RNN.  Further, while this isn't part of the competition, it is generally easier to provide an explanation of how a tree based model is making it's decisions over a NN, although IT IS possible, just more computationally expensive.\n",
    "\n",
    "This shows once again why I greatly prefer using LGBM when it makes sense.  Less data prep and trains much faster than XGboost.\n",
    "\n",
    "#### End of Review section by KL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# LightGBM Quickstart for the *American Express - Default Prediction* competition\n",
    "\n",
    "This notebook shows how to apply LightGBM to the competition data, and it introduces a space-efficient way of feature engineering.\n",
    "\n",
    "It is based on the [EDA which makes sense ⭐️⭐️⭐️⭐️⭐️](https://www.kaggle.com/code/ambrosm/amex-eda-which-makes-sense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-06-01T05:43:12.542621Z",
     "iopub.status.busy": "2022-06-01T05:43:12.542124Z",
     "iopub.status.idle": "2022-06-01T05:43:14.915294Z",
     "shell.execute_reply": "2022-06-01T05:43:14.914287Z",
     "shell.execute_reply.started": "2022-06-01T05:43:12.542534Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from cycler import cycler\n",
    "from IPython.display import display\n",
    "import datetime\n",
    "import scipy.stats\n",
    "import warnings\n",
    "from colorama import Fore, Back, Style\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from lightgbm import LGBMClassifier, log_evaluation\n",
    "\n",
    "plt.rcParams['axes.facecolor'] = '#0057b8' # blue\n",
    "plt.rcParams['axes.prop_cycle'] = cycler(color=['#ffd700'] +\n",
    "                                         plt.rcParams['axes.prop_cycle'].by_key()['color'][1:])\n",
    "plt.rcParams['text.color'] = 'w'\n",
    "\n",
    "INFERENCE = True # set to False if you only want to cross-validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-06-01T05:43:14.917129Z",
     "iopub.status.busy": "2022-06-01T05:43:14.91661Z",
     "iopub.status.idle": "2022-06-01T05:43:14.92935Z",
     "shell.execute_reply": "2022-06-01T05:43:14.928399Z",
     "shell.execute_reply.started": "2022-06-01T05:43:14.917101Z"
    }
   },
   "outputs": [],
   "source": [
    "#KL competition specific functions to score the results.\n",
    "\n",
    "def amex_metric(y_true, y_pred, return_components=False) -> float:\n",
    "    \"\"\"Amex metric for ndarrays\"\"\"\n",
    "    def top_four_percent_captured(df) -> float:\n",
    "        \"\"\"Corresponds to the recall for a threshold of 4 %\"\"\"\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(df) -> float:\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(df) -> float:\n",
    "        \"\"\"Corresponds to 2 * AUC - 1\"\"\"\n",
    "        df2 = pd.DataFrame({'target': df.target, 'prediction': df.target})\n",
    "        df2.sort_values('prediction', ascending=False, inplace=True)\n",
    "        return weighted_gini(df) / weighted_gini(df2)\n",
    "\n",
    "    df = pd.DataFrame({'target': y_true.ravel(), 'prediction': y_pred.ravel()})\n",
    "    df.sort_values('prediction', ascending=False, inplace=True)\n",
    "    g = normalized_weighted_gini(df)\n",
    "    d = top_four_percent_captured(df)\n",
    "\n",
    "    if return_components: return g, d, 0.5 * (g + d)\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "def lgb_amex_metric(y_true, y_pred):\n",
    "    \"\"\"The competition metric with lightgbm's calling convention\"\"\"\n",
    "    return ('amex',\n",
    "            amex_metric(y_true, y_pred),\n",
    "            True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and preprocessing the data\n",
    "\n",
    "We read the data from @munumbutt's [AMEX-Feather-Dataset](https://www.kaggle.com/datasets/munumbutt/amexfeather). Then we create two groups of features:\n",
    "- Selected features averaged over all statements of a customer\n",
    "- Selected features taken from the last statement of a customer\n",
    "\n",
    "The code has been optimized for memory efficiency rather than readability. In particular, `.iloc[mask_array, columns]` needs much less RAM than the groupby construction used in the previous version of the notebook.\n",
    "\n",
    "Preprocessing for LightGBM is much simpler than for neural networks:\n",
    "1. Neural networks can't process missing values; LightGBM handles them automatically.\n",
    "1. Categorical features need to be one-hot encoded for neural networks; LightGBM handles them automatically.\n",
    "1. With neural networks, you need to think about outliers; tree-based algorithms deal with outliers easily.\n",
    "1. Neural networks need scaled inputs; tree-based algorithms don't depend on scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T05:43:14.931074Z",
     "iopub.status.busy": "2022-06-01T05:43:14.930544Z",
     "iopub.status.idle": "2022-06-01T05:46:10.956818Z",
     "shell.execute_reply": "2022-06-01T05:46:10.955813Z",
     "shell.execute_reply.started": "2022-06-01T05:43:14.931042Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6d190dfbf191>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mINFERENCE\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_feather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'../input/amexfeather/{i}_data.ftr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;31m#KL pop will remove a column and return it as a pandas series object.  Very efficient.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mcid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'customer_ID'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\feather_format.py\u001b[0m in \u001b[0;36mread_feather\u001b[1;34m(path, columns, use_threads)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0mtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mstored\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \"\"\"\n\u001b[1;32m---> 98\u001b[1;33m     \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pyarrow\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mpyarrow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeather\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\compat\\_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, raise_on_missing, on_version)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraise_on_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow."
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "features_avg = ['B_1', 'B_11', 'B_16', 'B_17', 'B_18', 'B_2', 'B_20',\n",
    "                'B_28', 'B_3', 'B_4', 'B_5', 'B_7', 'B_9', 'D_112',\n",
    "                'D_121', 'D_141', 'D_39', 'D_41', 'D_42', 'D_43',\n",
    "                'D_44', 'D_45', 'D_46', 'D_47', 'D_48', 'D_49', \n",
    "                'D_50', 'D_51', 'D_53', 'D_54', 'D_56', 'D_58', \n",
    "                'D_59', 'D_60', 'D_91', 'P_2', 'P_3', 'R_1', 'R_2', \n",
    "                'R_27', 'R_3', 'R_7', 'S_11', 'S_26', 'S_3', 'S_5']\n",
    "features_max = ['B_1', 'B_11', 'B_13', 'B_15', 'B_16', 'B_17', 'B_18', 'B_19', 'B_2', \n",
    "                'B_22', 'B_24', 'B_27', 'B_28', 'B_29', 'B_3', 'B_31', 'B_33', 'B_36', \n",
    "                'B_4', 'B_42', 'B_5', 'B_7', 'B_9', 'D_102', 'D_103', 'D_105', 'D_109', \n",
    "                'D_110', 'D_112', 'D_113', 'D_115', 'D_121', 'D_124', 'D_128', 'D_129', \n",
    "                'D_131', 'D_139', 'D_141', 'D_144', 'D_145', 'D_39', 'D_41', 'D_42', \n",
    "                'D_43', 'D_44', 'D_45', 'D_46', 'D_47', 'D_48', 'D_50', 'D_51', 'D_52', \n",
    "                'D_53', 'D_56', 'D_58', 'D_59', 'D_60', 'D_62', 'D_70', 'D_72', 'D_74', \n",
    "                'D_75', 'D_79', 'D_81', 'D_83', 'D_84', 'D_88', 'D_89', 'P_2', 'P_3', \n",
    "                'R_1', 'R_10', 'R_11', 'R_26', 'R_28', 'R_3', 'R_4', 'R_5', 'R_7', 'R_8', \n",
    "                'S_11', 'S_12', 'S_23', 'S_25', 'S_26', 'S_27', 'S_3', 'S_5', 'S_7', 'S_8', ]\n",
    "features_last = ['B_1', 'B_10', 'B_11', 'B_12', 'B_13', 'B_15', 'B_16',\n",
    "                 'B_17', 'B_18', 'B_19', 'B_2', 'B_20', 'B_22', 'B_23',\n",
    "                 'B_24', 'B_25', 'B_26', 'B_27', 'B_28', 'B_29', 'B_3',\n",
    "                 'B_32', 'B_33', 'B_36', 'B_38', 'B_39', 'B_4', 'B_40',\n",
    "                 'B_41', 'B_42', 'B_5', 'B_6', 'B_7', 'B_8', 'B_9',\n",
    "                 'D_102', 'D_103', 'D_105', 'D_106', 'D_107', 'D_109',\n",
    "                 'D_112', 'D_115', 'D_117', 'D_118', 'D_119', 'D_120',\n",
    "                 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_127', \n",
    "                 'D_129', 'D_132', 'D_133', 'D_135', 'D_136', 'D_137', \n",
    "                 'D_140', 'D_141', 'D_143', 'D_145', 'D_39', 'D_41',\n",
    "                 'D_42', 'D_43', 'D_44', 'D_45', 'D_46', 'D_47', 'D_48',\n",
    "                 'D_49', 'D_50', 'D_51', 'D_52', 'D_53', 'D_54', 'D_55',\n",
    "                 'D_56', 'D_58', 'D_59', 'D_60', 'D_61', 'D_62', 'D_63',\n",
    "                 'D_64', 'D_66', 'D_70', 'D_72', 'D_73', 'D_74', 'D_75',\n",
    "                 'D_76', 'D_77', 'D_78', 'D_79', 'D_80', 'D_82', 'D_83',\n",
    "                 'D_84', 'D_86', 'D_91', 'D_92', 'D_93', 'D_94', 'D_96',\n",
    "                 'P_2', 'P_3', 'R_1', 'R_10', 'R_11', 'R_12', 'R_13',\n",
    "                 'R_14', 'R_15', 'R_17', 'R_18', 'R_19', 'R_2', 'R_20', \n",
    "                 'R_21', 'R_22', 'R_24', 'R_25', 'R_26', 'R_27', 'R_3',\n",
    "                 'R_4', 'R_5', 'R_7', 'R_8', 'R_9', 'S_11', 'S_12',\n",
    "                 'S_13', 'S_15', 'S_17', 'S_20', 'S_22', 'S_23', \n",
    "                 'S_24', 'S_25', 'S_26', 'S_27', 'S_3', 'S_5', 'S_6',\n",
    "                 'S_7', 'S_8', 'S_9']\n",
    "\n",
    "for i in ['test', 'train'] if INFERENCE else ['train']:\n",
    "    df = pd.read_feather(f'../input/amexfeather/{i}_data.ftr')\n",
    "    #KL pop will remove a column and return it as a pandas series object.  Very efficient.\n",
    "    cid = pd.Categorical(df.pop('customer_ID'), ordered=True)\n",
    "    #kl np.roll Roll array elements along a given axis.\n",
    "    last = (cid != np.roll(cid, -1)) # mask for last statement of every customer\n",
    "    if i == 'train':\n",
    "        target = df.loc[last, 'target']\n",
    "        df.drop(columns=['target'], inplace=True)\n",
    "    #klgc.collect() performs a garbage collection of all generations, reclaims max amount of memory.\n",
    "    gc.collect()\n",
    "    print('Read', i)\n",
    "    #klSome feature creation here, averaging or maxing features from all of the different statements\n",
    "    df_avg = (df\n",
    "              .groupby(cid)\n",
    "              .mean()[features_avg]\n",
    "              .rename(columns={f: f\"{f}_avg\" for f in features_avg})\n",
    "             )\n",
    "    gc.collect()\n",
    "    print('Computed avg', i)\n",
    "    df_max = (df\n",
    "              .groupby(cid)\n",
    "              .max()[features_max]\n",
    "              .rename(columns={f: f\"{f}_max\" for f in features_max})\n",
    "             )\n",
    "    gc.collect()\n",
    "    print('Computed max', i)\n",
    "    df = (df.loc[last, features_last]\n",
    "          .rename(columns={f: f\"{f}_last\" for f in features_last})\n",
    "          .set_index(np.asarray(cid[last]))\n",
    "         )\n",
    "    gc.collect()\n",
    "    print('Computed last', i)\n",
    "    df = pd.concat([df, df_max, df_avg], axis=1)\n",
    "    if i == 'train': train = df\n",
    "    else: test = df\n",
    "    print(f\"{i} shape: {df.shape}\")\n",
    "    del df, df_avg, df_max, cid, last\n",
    "\n",
    "#print('Shapes:', train.shape, target.shape)\n",
    "print(f\"target shape: {target.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation\n",
    "\n",
    "We cross-validate with a five-fold StratifiedKFold.\n",
    "\n",
    "Notice that lightgbm logs the validation score with the competition's scoring function every hundred iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T05:46:10.959676Z",
     "iopub.status.busy": "2022-06-01T05:46:10.959056Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cross-validation of the classifier\n",
    "\n",
    "ONLY_FIRST_FOLD = False\n",
    "\n",
    "features = [f for f in train.columns if f != 'customer_ID' and f != 'target']\n",
    "#KL the values appear to be tuned, but I don't see any discussion of running a hyperparamter optimization.\n",
    "#would be a good place to start to optimize.\n",
    "def my_booster(random_state=1, n_estimators=1150):\n",
    "    return LGBMClassifier(n_estimators=n_estimators,\n",
    "                          learning_rate=0.03, reg_lambda=50,\n",
    "                          min_child_samples=2400,\n",
    "                          num_leaves=95,\n",
    "                          max_bins=511, random_state=random_state)\n",
    "      \n",
    "print(f\"{len(features)} features\")\n",
    "score_list = []\n",
    "y_pred_list = []\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(train, target)):\n",
    "    start_time = datetime.datetime.now()\n",
    "    X_tr = train.iloc[idx_tr][features]\n",
    "    X_va = train.iloc[idx_va][features]\n",
    "    y_tr = target.iloc[idx_tr]\n",
    "    y_va = target.iloc[idx_va]\n",
    "    \n",
    "    model = my_booster()\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        model.fit(X_tr, y_tr,\n",
    "                  eval_set = [(X_tr, y_tr),(X_va, y_va)], \n",
    "                  eval_metric=[lgb_amex_metric],\n",
    "                  callbacks=[log_evaluation(100)])\n",
    "    y_va_pred = model.predict_proba(X_va)[:,1]\n",
    "    score = amex_metric(y_va.values, y_va_pred)\n",
    "    n_trees = model.best_iteration_\n",
    "    if n_trees is None: n_trees = model.n_estimators\n",
    "    print(f\"{Fore.GREEN}{Style.BRIGHT}Fold {fold} | {str(datetime.datetime.now() - start_time)[-12:-7]} |\"\n",
    "          f\" {n_trees:5} trees |\"\n",
    "          f\"                Score = {score:.5f}{Style.RESET_ALL}\")\n",
    "    score_list.append(score)\n",
    "    \n",
    "    if INFERENCE:\n",
    "        y_pred_list.append(model.predict_proba(test[features])[:,1])\n",
    "        \n",
    "    if ONLY_FIRST_FOLD: break # we only want the first fold\n",
    "    \n",
    "print(f\"{Fore.GREEN}{Style.BRIGHT}OOF Score:                       {np.mean(score_list):.5f}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(y_va_pred[y_va == 0], bins=np.linspace(0, 1, 21),\n",
    "         alpha=0.5, density=True, label='0')\n",
    "plt.hist(y_va_pred[y_va == 1], bins=np.linspace(0, 1, 21),\n",
    "         alpha=0.5, density=True, label='1')\n",
    "plt.xlabel('y_pred')\n",
    "plt.ylabel('density')\n",
    "plt.title('OOF Prediction histogram', color='k')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration diagram\n",
    "\n",
    "The calibration diagram shows how the model predicts the default probability of customers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "CalibrationDisplay.from_predictions(y_va, y_va_pred, n_bins=50, strategy='quantile', ax=plt.gca())\n",
    "plt.title('Probability calibration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "We submit the mean of the five predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INFERENCE:\n",
    "    sub = pd.DataFrame({'customer_ID': test.index,\n",
    "                        'prediction': np.mean(y_pred_list, axis=0)})\n",
    "    sub.to_csv('submission.csv', index=False)\n",
    "    display(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
