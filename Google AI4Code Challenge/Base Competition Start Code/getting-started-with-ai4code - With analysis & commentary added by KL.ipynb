{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KL - Notebook Review  5/31/2022\n",
    "\n",
    "Original link to notebook reviewed here https://www.kaggle.com/code/ryanholbrook/getting-started-with-ai4code/notebook\n",
    "\n",
    "I reviewed this notebook as part of a personal improvement project to refresh and grow my data science skills by exposure and review of cutting edge publically available notebooks.  This specific notebook below is part of a Kaggle competition by google to create a model that can, given all the cells in a randomly shuffled data science notebook, correctly rank and reorder the cells.\n",
    "\n",
    "The top 2 markdown cells in this notebook were created by me to house my general notes, throughout the rest of the notebook my comments are identified by a 'KL' to differentiate from the comments provided by the notebook's author (google).  The primary purpose of this exercise is my own learning, and so comments will be informal and at what I thought was interesting at the time.\n",
    "\n",
    "-------\n",
    "\n",
    "This initial notebook provided by google's team is what you would expect.  It uses a pretty basic model (xgboost)\n",
    "and a small training size of 10k out of the 139k provided.\n",
    "\n",
    "## Initial Thoughts after notebook review:\n",
    "\n",
    "\n",
    "## Quick list to increase accuracy \n",
    "\n",
    "\n",
    " * Try reducing from 0.01 for min weight in the tf-idf vectorizor\n",
    " * Use full training data set\n",
    " * Switch from XGBoost to LGBM to decrease training speed which maintaining same level of accuracy \n",
    " * Try a grid-search on the LGBM hyperparameters.\n",
    "\n",
    "\n",
    "## More intensive list to increase accuracy\n",
    "\n",
    "\n",
    " * Add more features, use a different method of tokenization/converting the text to features\n",
    " * use 2 or 3 n grams, split up the words using periods to seperate\n",
    " * add custom features for common libraries to indicate if they are present in that code block.\n",
    " * Use whatever the most common version of BERT is\n",
    "\n",
    "I don't think training a neural net from scratch makes sense for this, as if you are going to do a deep learning NN you\n",
    "might as well use BERT.\n",
    "\n",
    "\n",
    "## VERY INTENSE method to increase accuracy\n",
    "\n",
    "\n",
    " Use a BERT derivative to generate features for the code, combine those with my custom features, then train a NN to rank.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL - Notes after examining top open source competition code. 6/31/2022\n",
    "\n",
    "\n",
    "## Detailed EDA\n",
    "https://www.kaggle.com/code/odins0n/ai4code-detailed-eda\n",
    "\n",
    "This notebook has some great EDA on the dataset, and is a reminder to always look around for available resources and documentation on data as part of any project.\n",
    " \n",
    "Also has some good code to work off of for any in-notebook EDA in the future, although personally I generally prefer an\n",
    "approach of doing personal EDA within the notebook, but exporting an aggregation to microsoft excel and doing\n",
    "visualizations for other parties in there, due to my familiarity with advanced excel visualziation techniques.\n",
    "\n",
    "## DistilBert\n",
    "https://www.kaggle.com/code/aerdem4/ai4code-pytorch-distilbert-baseline\n",
    "\n",
    "This is a great notebook that goes along with my initial intution, that a BERT derivative should be suitable for this \n",
    "project.  I did my capstone project for my Master's Degree using BERT, and so I knew it would be a good start for any complex analysis of text due to the sophisticated way it has learned and can represent text.\n",
    "\n",
    "In this case, the author used the initial getting-started-with-ai4code notebook (the notebook i'm writing this in)\n",
    "but used a DistilBert model.  While other BERT derivatives are going to be more powerful, DistilBert is going to be more \n",
    "efficient, which is important considering the competition guidelines that the code can be run on kaggle cloud in a \n",
    "reasonable time.\n",
    "\n",
    "Sadly, the author did not provide comments in the code, but it would be a good starting place for future work on this competition.\n",
    "\n",
    "### Overall\n",
    "\n",
    "Main lessons to learn here are some great methods to use in efficiently preparing text as well as data preperation of text.  It's also a fantastic example of using itertuples over iterrows which can save a great deal of run-time.\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Google AI4Code Competition! #\n",
    "\n",
    "In this competition you're challenged to reconstruct the order of Kaggle notebooks whose cells have been shuffled. Check out the [Competition Pages](https://www.kaggle.com/competitions/AI4Code/overview) for a complete overview.\n",
    "\n",
    "This notebook will walk you through making a submission with a simple ranking model. We'll look at how to:\n",
    "- Wrangle the competition data and create validation splits,\n",
    "- Represent the code cell orders with a feature,\n",
    "- Build a ranking model with XGBoost,\n",
    "- Evaluate predictions with a Python implementation of the competition metric, and,\n",
    "- Format predictions to make a successful submission.\n",
    "\n",
    "Our model will be able to learn roughly where a cell should go in a notebook based on what words it contains -- that, for example, cells containing \"Introduction\" or `import` should usually be near the beginning, while cells containing \"Submit\" or `submission.csv` should usually be near the end. These simple features are effective at reconstructing the global order of typical data science workflows. An understanding of the *interactions* or *relationships between cells*, however, will be required of the most successful solutions. We encourage you therefore to explore things like modern neural network language models for learning the relationships between natural language and computer code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#KL - This code is provided by google to assist with starting the project.\n",
    "#All code comments with KL were provided by me\n",
    "\n",
    "#Standard library import.  The files are stored as JSON files.\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "#KL this an option that i wish I had learned when i first started.\n",
    "#Expanding the number of default dataframe columns/rows can be extremely helpful during data exploration.\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "data_dir = Path('YOURPATHHERE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebooks are stored as individiual JSON files. They've been cleaned of the usual metadata present in Jupyter notebooks, leaving only the `cell_type` and `source`. The [Data](https://www.kaggle.com/competitions/AI4Code/data) page on the competition website has the full documentation of this dataset.\n",
    "\n",
    "We'll load the notebooks here and join them into a dataframe for easier processing. The full set of training data takes quite a while to load, so we'll just use a subset for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train NBs: 100%|████████████████████████████████████████████████████████████████| 10000/10000 [01:01<00:00, 162.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">00001756c60be8</th>\n",
       "      <th>1862f0a6</th>\n",
       "      <td>code</td>\n",
       "      <td># This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2a9e43d6</th>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimport random\\n\\nfrom sklearn.model_selection import train_test_split, cros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>038b763d</th>\n",
       "      <td>code</td>\n",
       "      <td>import warnings\\nwarnings.filterwarnings('ignore')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2eefe0ef</th>\n",
       "      <td>code</td>\n",
       "      <td>matplotlib.rcParams.update({'font.size': 14})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0beab1cd</th>\n",
       "      <td>code</td>\n",
       "      <td>def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\\n    print(\"Train R2:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">125ef3d1595c5d</th>\n",
       "      <th>653dad94</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## 10. Making predictions and evaluating performance\\n&lt;p&gt;But how well does our model perform? &lt;/p&gt;\\n&lt;p&gt;We will now e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19e283d7</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## 5. Handling the missing values (part iii)\\n&lt;p&gt;We have successfully taken care of the missing values present in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4d70f32</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## 9. Fitting a logistic regression model to the train set\\n&lt;p&gt;Essentially, predicting if a credit card application ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7981b5de</th>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;p&gt;In this small project I will build a  supervised machine learning model to predict if a credit card application w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4a20230b</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## 7. Splitting the dataset into train and test sets\\n&lt;p&gt;We have successfully converted all the non-numeric values t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>461759 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        cell_type                                                                                                                   source\n",
       "id             cell_id                                                                                                                                    \n",
       "00001756c60be8 1862f0a6      code  # This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...\n",
       "               2a9e43d6      code  import numpy as np\\nimport pandas as pd\\nimport random\\n\\nfrom sklearn.model_selection import train_test_split, cros...\n",
       "               038b763d      code                                                                       import warnings\\nwarnings.filterwarnings('ignore')\n",
       "               2eefe0ef      code                                                                            matplotlib.rcParams.update({'font.size': 14})\n",
       "               0beab1cd      code  def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\\n    print(\"Train R2:\\...\n",
       "...                           ...                                                                                                                      ...\n",
       "125ef3d1595c5d 653dad94  markdown  ## 10. Making predictions and evaluating performance\\n<p>But how well does our model perform? </p>\\n<p>We will now e...\n",
       "               19e283d7  markdown  ## 5. Handling the missing values (part iii)\\n<p>We have successfully taken care of the missing values present in th...\n",
       "               c4d70f32  markdown  ## 9. Fitting a logistic regression model to the train set\\n<p>Essentially, predicting if a credit card application ...\n",
       "               7981b5de  markdown  <p>In this small project I will build a  supervised machine learning model to predict if a credit card application w...\n",
       "               4a20230b  markdown  ## 7. Splitting the dataset into train and test sets\\n<p>We have successfully converted all the non-numeric values t...\n",
       "\n",
       "[461759 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KL as this is an example notebook, only 10k samples are chosen.\n",
    "#this would obviously be an important variable to change for the real deal.\n",
    "\n",
    "NUM_TRAIN = 10000\n",
    "\n",
    "#KL this function takes a given file path, reads in the json, and returns it while also giving the data types\n",
    "#and taking the stem of the file path, or the file name for that particular file, and assigning it as the ID\n",
    "\n",
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(\n",
    "            path,\n",
    "            dtype={'cell_type': 'category', 'source': 'str'})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis('cell_id')\n",
    "    )\n",
    "\n",
    "#KL this code uses 'glob' to do a wildcard search for all files in the the folder 'train' that end in .json'\n",
    "#it then converts that to a list\n",
    "paths_train = list((data_dir / 'train').glob('*.json'))[:NUM_TRAIN]\n",
    "\n",
    "#KL we use the function we defined earlier, for each file path we created\n",
    "#TQDM is used to provide the helpful progress bar\n",
    "\n",
    "notebooks_train = [\n",
    "    read_notebook(path) for path in tqdm(paths_train, desc='Train NBs')\n",
    "]\n",
    "\n",
    "#KL We create our master dataframe by concating the json files we just read in.\n",
    "#we set the index as the ID, which leaves us with the colums of 'cell_id' 'cell_type' (Code or markdown)\n",
    "#and 'source' which is the actual text of the column.\n",
    "#note that this means that we have multiple rows with the same index.  Presumably the ID refers to the ID of the notebook as a whole.\n",
    "#we also sorted by the index of the notebook.\n",
    "\n",
    "df = (\n",
    "    pd.concat(notebooks_train)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each notebook has all the code cells given first with the markdown cells following. The code cells are in the correct relative order, while the markdown cells are shuffled. In the next section, we'll see how to recover the correct orderings for notebooks in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook: 00038c2941faa0\n",
      "The disordered notebook:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3e551fb7</th>\n",
       "      <td>code</td>\n",
       "      <td># This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45049ad8</th>\n",
       "      <td>code</td>\n",
       "      <td>train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123b4f4c</th>\n",
       "      <td>code</td>\n",
       "      <td>import plotly.express as px</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0b92cb59</th>\n",
       "      <td>code</td>\n",
       "      <td>train_data.head(20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df963df4</th>\n",
       "      <td>code</td>\n",
       "      <td>train_data.isnull().sum()  #checking out which column has most no. of NaN Values</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0f3db81b</th>\n",
       "      <td>code</td>\n",
       "      <td>px.bar(data_frame=train_data, x='Sex', y='Survived',color='Sex',facet_row_spacing=0, title=\"Relation between Gender ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33ff3073</th>\n",
       "      <td>code</td>\n",
       "      <td>total_passengers = train_data['Sex'].count()\\ncount_males = 0\\ncount_females = 0\\nfor i,j in zip(train_data['Sex'], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818c4c15</th>\n",
       "      <td>code</td>\n",
       "      <td>from sklearn.ensemble import RandomForestClassifier\\n\\n\\ny = train_data[\"Survived\"]\\n\\nfeatures = [\"Pclass\", \"Sex\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6cfbe868</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## Survival Rate for Male Passenger is : 12.235 %\\n\\n## Survival Rate for Female Passenger is : 26.150 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eadf5c66</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## Who has more luck in here? \\n\\n\\nFrom the above data we can find out that females had more survival rate on Titan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3c7d19bc</th>\n",
       "      <td>markdown</td>\n",
       "      <td>From the above inference Cabin needs to be either dropped or needs to be filled with Appropriate values</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5a8b6e2d</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## EDA is all about asking the right questions\\n\\nWhat are some questions that come to your mind when you're checkin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8bb41691</th>\n",
       "      <td>markdown</td>\n",
       "      <td>### Checking out the Titanic Dataset \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88cc83b2</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Machine Learning Model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_type                                                                                                                   source\n",
       "cell_id                                                                                                                                    \n",
       "3e551fb7      code  # This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...\n",
       "45049ad8      code   train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
       "123b4f4c      code                                                                                              import plotly.express as px\n",
       "0b92cb59      code                                                                                                      train_data.head(20)\n",
       "df963df4      code                                         train_data.isnull().sum()  #checking out which column has most no. of NaN Values\n",
       "0f3db81b      code  px.bar(data_frame=train_data, x='Sex', y='Survived',color='Sex',facet_row_spacing=0, title=\"Relation between Gender ...\n",
       "33ff3073      code  total_passengers = train_data['Sex'].count()\\ncount_males = 0\\ncount_females = 0\\nfor i,j in zip(train_data['Sex'], ...\n",
       "818c4c15      code  from sklearn.ensemble import RandomForestClassifier\\n\\n\\ny = train_data[\"Survived\"]\\n\\nfeatures = [\"Pclass\", \"Sex\", ...\n",
       "6cfbe868  markdown                 ## Survival Rate for Male Passenger is : 12.235 %\\n\\n## Survival Rate for Female Passenger is : 26.150 %\n",
       "eadf5c66  markdown  ## Who has more luck in here? \\n\\n\\nFrom the above data we can find out that females had more survival rate on Titan...\n",
       "3c7d19bc  markdown                  From the above inference Cabin needs to be either dropped or needs to be filled with Appropriate values\n",
       "5a8b6e2d  markdown  ## EDA is all about asking the right questions\\n\\nWhat are some questions that come to your mind when you're checkin...\n",
       "8bb41691  markdown                                                                                  ### Checking out the Titanic Dataset \\n\n",
       "88cc83b2  markdown                                                                                                 # Machine Learning Model"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get an example notebook\n",
    "nb_id = df.index.unique('id')[6]\n",
    "print('Notebook:', nb_id)\n",
    "\n",
    "print(\"The disordered notebook:\")\n",
    "nb = df.loc[nb_id, :]\n",
    "display(nb)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task in this competition is to predict the correct order of the notebook cells, both code and markdown. Since you're given the relative ordering of the code cells among themselves, you could also think of this as predicting where the markdown cells should be placed among the code cells.\n",
    "\n",
    "For example, a disordered notebook might be:\n",
    "```\n",
    "code_1\n",
    "code_2\n",
    "code_3\n",
    "markdown_1\n",
    "markdown_2\n",
    "```\n",
    "and the correctly ordered notebook might be:\n",
    "```\n",
    "code_1\n",
    "markdown_2\n",
    "code_2\n",
    "code_3\n",
    "markdown_1\n",
    "```\n",
    "The markdown cells can be in any order, but you would never see `code_2` before `code_1`, for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordering the Cells #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `train_orders.csv` file we have, for notebooks in the training set, the correct ordering of cells in terms of the cell ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "00001756c60be8    [1862f0a6, 448eb224, 2a9e43d6, 7e2f170a, 038b763d, 77e56113, 2eefe0ef, 1ae087ab, 0beab1cd, 8ffe0b25, 9a78ab76, 0d136...\n",
       "00015c83e2717b    [2e94bd7a, 3e99dee9, b5e286ea, da4f7550, c417225b, 51e3cd89, 2600b4eb, 75b65993, cf195f8b, 25699d02, 72b3201a, f2c75...\n",
       "0001bdd4021779    [3fdc37be, 073782ca, 8ea7263c, 80543cd8, 38310c80, 073e27e5, 015d52a4, ad7679ef, 7fde4f04, 07c52510, 0a1a7a39, 0bcd3...\n",
       "0001daf4c2c76d    [97266564, a898e555, 86605076, 76cc2642, ef279279, df6c939f, 2476da96, 00f87d0a, ae93e8e6, 58aadb1d, d20b0094, 986fd...\n",
       "0002115f48f982                                 [9ec225f0, 18281c6c, e3b6b115, 4a044c54, 365fe576, a3188e54, b3f6e12d, ee7655ca, 84125b7a]\n",
       "                                                                           ...                                                           \n",
       "fffc30d5a0bc46    [09727c0c, ff1ea6a0, ddfef603, a01ce9b3, 3ba953ee, bf92a015, f4a0492a, 095812e6, 53125cfe, aa32a700, 63340e73, 06d8c...\n",
       "fffc3b44869198    [978a5137, faa48f03, 28dfb12a, eea2e812, 64fef97c, 4e0d1510, 58e68f2c, 8784e700, 4bd5a4cf, dc14bfec, 2aff7603, 8047d...\n",
       "fffc63ff750064    [5015c300, 411b85d9, 8238198c, f4781d1d, b5532930, e1f223e5, e7e67119, 4aaf741d, 7229cce6, a7fa3628, e4c2fa86, 1f8f9...\n",
       "fffcd063cda949    [7e6266ad, d8281fc5, d4ffcaef, 3e0e4a47, 21387fc8, cc229f9a, baed9c8b, d1bb21aa, 82979992, 65f95dad, eba4fa9e, c97e2...\n",
       "fffe1d764579d5    [1a63248d, 9c3b96a5, 1398a873, 4e2d4c2d, f71c538e, 8b44a5e8, 385dff7a, b8254ef8, 4d0e433e, debc496c, e15ae953, e4d79...\n",
       "Name: cell_order, Length: 139256, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KL read the csv file 'train_orders.csv'\n",
    "#after reviewing this file manually, it consists of 2 columns 'id' and 'cell_order'\n",
    "#the ID column has 1 value, the unique ID of the notebook.\n",
    "# the cell_order column has multiple values seperated by a single space, this are the cell_ids of all cells in the that notebook.\n",
    "#note that while the input csv file has 2 columns, we are using 1 for the index.\n",
    "#this means when we pass in \"squeeze\" = True that it will convert the input into a list.\n",
    "df_orders = pd.read_csv(\n",
    "    data_dir / 'train_orders.csv',\n",
    "    index_col='id',\n",
    "    squeeze=True,\n",
    ").str.split()  # Split the string representation of cell_ids into a list\n",
    "\n",
    "df_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ordered notebook:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3e551fb7</th>\n",
       "      <td>code</td>\n",
       "      <td># This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45049ad8</th>\n",
       "      <td>code</td>\n",
       "      <td>train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8bb41691</th>\n",
       "      <td>markdown</td>\n",
       "      <td>### Checking out the Titanic Dataset \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123b4f4c</th>\n",
       "      <td>code</td>\n",
       "      <td>import plotly.express as px</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0b92cb59</th>\n",
       "      <td>code</td>\n",
       "      <td>train_data.head(20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5a8b6e2d</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## EDA is all about asking the right questions\\n\\nWhat are some questions that come to your mind when you're checkin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df963df4</th>\n",
       "      <td>code</td>\n",
       "      <td>train_data.isnull().sum()  #checking out which column has most no. of NaN Values</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3c7d19bc</th>\n",
       "      <td>markdown</td>\n",
       "      <td>From the above inference Cabin needs to be either dropped or needs to be filled with Appropriate values</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0f3db81b</th>\n",
       "      <td>code</td>\n",
       "      <td>px.bar(data_frame=train_data, x='Sex', y='Survived',color='Sex',facet_row_spacing=0, title=\"Relation between Gender ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eadf5c66</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## Who has more luck in here? \\n\\n\\nFrom the above data we can find out that females had more survival rate on Titan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33ff3073</th>\n",
       "      <td>code</td>\n",
       "      <td>total_passengers = train_data['Sex'].count()\\ncount_males = 0\\ncount_females = 0\\nfor i,j in zip(train_data['Sex'], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6cfbe868</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## Survival Rate for Male Passenger is : 12.235 %\\n\\n## Survival Rate for Female Passenger is : 26.150 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88cc83b2</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Machine Learning Model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818c4c15</th>\n",
       "      <td>code</td>\n",
       "      <td>from sklearn.ensemble import RandomForestClassifier\\n\\n\\ny = train_data[\"Survived\"]\\n\\nfeatures = [\"Pclass\", \"Sex\", ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_type                                                                                                                   source\n",
       "cell_id                                                                                                                                    \n",
       "3e551fb7      code  # This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...\n",
       "45049ad8      code   train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
       "8bb41691  markdown                                                                                  ### Checking out the Titanic Dataset \\n\n",
       "123b4f4c      code                                                                                              import plotly.express as px\n",
       "0b92cb59      code                                                                                                      train_data.head(20)\n",
       "5a8b6e2d  markdown  ## EDA is all about asking the right questions\\n\\nWhat are some questions that come to your mind when you're checkin...\n",
       "df963df4      code                                         train_data.isnull().sum()  #checking out which column has most no. of NaN Values\n",
       "3c7d19bc  markdown                  From the above inference Cabin needs to be either dropped or needs to be filled with Appropriate values\n",
       "0f3db81b      code  px.bar(data_frame=train_data, x='Sex', y='Survived',color='Sex',facet_row_spacing=0, title=\"Relation between Gender ...\n",
       "eadf5c66  markdown  ## Who has more luck in here? \\n\\n\\nFrom the above data we can find out that females had more survival rate on Titan...\n",
       "33ff3073      code  total_passengers = train_data['Sex'].count()\\ncount_males = 0\\ncount_females = 0\\nfor i,j in zip(train_data['Sex'], ...\n",
       "6cfbe868  markdown                 ## Survival Rate for Male Passenger is : 12.235 %\\n\\n## Survival Rate for Female Passenger is : 26.150 %\n",
       "88cc83b2  markdown                                                                                                 # Machine Learning Model\n",
       "818c4c15      code  from sklearn.ensemble import RandomForestClassifier\\n\\n\\ny = train_data[\"Survived\"]\\n\\nfeatures = [\"Pclass\", \"Sex\", ..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the correct order\n",
    "cell_order = df_orders.loc[nb_id]\n",
    "\n",
    "print(\"The ordered notebook:\")\n",
    "nb.loc[cell_order, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct numeric position of a cell we will call the **rank** of the cell. We can find the ranks of the cells within a notebook by referencing the true ordering of cell ids as given in `train_orders.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3e551fb7</th>\n",
       "      <td>0</td>\n",
       "      <td>code</td>\n",
       "      <td># This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45049ad8</th>\n",
       "      <td>1</td>\n",
       "      <td>code</td>\n",
       "      <td>train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123b4f4c</th>\n",
       "      <td>3</td>\n",
       "      <td>code</td>\n",
       "      <td>import plotly.express as px</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0b92cb59</th>\n",
       "      <td>4</td>\n",
       "      <td>code</td>\n",
       "      <td>train_data.head(20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df963df4</th>\n",
       "      <td>6</td>\n",
       "      <td>code</td>\n",
       "      <td>train_data.isnull().sum()  #checking out which column has most no. of NaN Values</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0f3db81b</th>\n",
       "      <td>8</td>\n",
       "      <td>code</td>\n",
       "      <td>px.bar(data_frame=train_data, x='Sex', y='Survived',color='Sex',facet_row_spacing=0, title=\"Relation between Gender ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33ff3073</th>\n",
       "      <td>10</td>\n",
       "      <td>code</td>\n",
       "      <td>total_passengers = train_data['Sex'].count()\\ncount_males = 0\\ncount_females = 0\\nfor i,j in zip(train_data['Sex'], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818c4c15</th>\n",
       "      <td>13</td>\n",
       "      <td>code</td>\n",
       "      <td>from sklearn.ensemble import RandomForestClassifier\\n\\n\\ny = train_data[\"Survived\"]\\n\\nfeatures = [\"Pclass\", \"Sex\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6cfbe868</th>\n",
       "      <td>11</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Survival Rate for Male Passenger is : 12.235 %\\n\\n## Survival Rate for Female Passenger is : 26.150 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eadf5c66</th>\n",
       "      <td>9</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Who has more luck in here? \\n\\n\\nFrom the above data we can find out that females had more survival rate on Titan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3c7d19bc</th>\n",
       "      <td>7</td>\n",
       "      <td>markdown</td>\n",
       "      <td>From the above inference Cabin needs to be either dropped or needs to be filled with Appropriate values</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5a8b6e2d</th>\n",
       "      <td>5</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## EDA is all about asking the right questions\\n\\nWhat are some questions that come to your mind when you're checkin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8bb41691</th>\n",
       "      <td>2</td>\n",
       "      <td>markdown</td>\n",
       "      <td>### Checking out the Titanic Dataset \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88cc83b2</th>\n",
       "      <td>12</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Machine Learning Model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rank cell_type                                                                                                                   source\n",
       "cell_id                                                                                                                                          \n",
       "3e551fb7     0      code  # This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...\n",
       "45049ad8     1      code   train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
       "123b4f4c     3      code                                                                                              import plotly.express as px\n",
       "0b92cb59     4      code                                                                                                      train_data.head(20)\n",
       "df963df4     6      code                                         train_data.isnull().sum()  #checking out which column has most no. of NaN Values\n",
       "0f3db81b     8      code  px.bar(data_frame=train_data, x='Sex', y='Survived',color='Sex',facet_row_spacing=0, title=\"Relation between Gender ...\n",
       "33ff3073    10      code  total_passengers = train_data['Sex'].count()\\ncount_males = 0\\ncount_females = 0\\nfor i,j in zip(train_data['Sex'], ...\n",
       "818c4c15    13      code  from sklearn.ensemble import RandomForestClassifier\\n\\n\\ny = train_data[\"Survived\"]\\n\\nfeatures = [\"Pclass\", \"Sex\", ...\n",
       "6cfbe868    11  markdown                 ## Survival Rate for Male Passenger is : 12.235 %\\n\\n## Survival Rate for Female Passenger is : 26.150 %\n",
       "eadf5c66     9  markdown  ## Who has more luck in here? \\n\\n\\nFrom the above data we can find out that females had more survival rate on Titan...\n",
       "3c7d19bc     7  markdown                  From the above inference Cabin needs to be either dropped or needs to be filled with Appropriate values\n",
       "5a8b6e2d     5  markdown  ## EDA is all about asking the right questions\\n\\nWhat are some questions that come to your mind when you're checkin...\n",
       "8bb41691     2  markdown                                                                                  ### Checking out the Titanic Dataset \\n\n",
       "88cc83b2    12  markdown                                                                                                 # Machine Learning Model"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KL helpful little function.\n",
    "#essentially takes the index of each row grouped in the same index, and returns it\n",
    "\n",
    "def get_ranks(base, derived):\n",
    "    return [base.index(d) for d in derived]\n",
    "\n",
    "#KL then we use the function on the cellorder list, which returns the rank of each cell within a specific 'index' or notebookid\n",
    "\n",
    "cell_ranks = get_ranks(cell_order, list(nb.index))\n",
    "nb.insert(0, 'rank', cell_ranks)\n",
    "\n",
    "nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting a notebook by the cell ranks is another way to order the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#KL assert frame equal lets you know if there any differences between a left and right dataframe\n",
    "from pandas.testing import assert_frame_equal\n",
    "#KL I added print statement\n",
    "print(assert_frame_equal(nb.loc[cell_order, :], nb.sort_values('rank')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm we'll be using for our baseline model uses the cell ranks as the target, so let's create a dataframe of the ranks for each notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">00001756c60be8</th>\n",
       "      <th>1862f0a6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2a9e43d6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>038b763d</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2eefe0ef</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0beab1cd</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">125ef3d1595c5d</th>\n",
       "      <th>653dad94</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19e283d7</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4d70f32</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7981b5de</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4a20230b</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>461759 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        rank\n",
       "id             cell_id      \n",
       "00001756c60be8 1862f0a6    0\n",
       "               2a9e43d6    2\n",
       "               038b763d    4\n",
       "               2eefe0ef    6\n",
       "               0beab1cd    8\n",
       "...                      ...\n",
       "125ef3d1595c5d 653dad94   20\n",
       "               19e283d7   10\n",
       "               c4d70f32   18\n",
       "               7981b5de    0\n",
       "               4a20230b   14\n",
       "\n",
       "[461759 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KL To frame converts a series object to a dataframe. \n",
    "#Here we convert DF orders which is the original reading in of the cells\n",
    "\n",
    "df_orders_ = df_orders.to_frame().join(\n",
    "    df.reset_index('cell_id').groupby('id')['cell_id'].apply(list),\n",
    "    how='right',\n",
    ")\n",
    "\n",
    "ranks = {}\n",
    "#KL itertuples is a way of getting a named tuple for each row, and is much faster than using iterrows\n",
    "#in this case the tuple is the notebook id, the cell id, and the rank.\n",
    "#we then reapply the get_ranks function we defined earlier.\n",
    "\n",
    "for id_, cell_order, cell_id in df_orders_.itertuples():\n",
    "    ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)}\n",
    "\n",
    "#the end result is a dictionary of the cell_id and rank within the notebook that cell_id came from.    \n",
    "    \n",
    "df_ranks = (\n",
    "    pd.DataFrame\n",
    "    .from_dict(ranks, orient='index')\n",
    "    .rename_axis('id')\n",
    "    .apply(pd.Series.explode)\n",
    "    .set_index('cell_id', append=True)\n",
    ")\n",
    "\n",
    "\n",
    "#KL The end result is a pandas dataframe with TWO indexes, and 1 column.\n",
    "df_ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splits #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `df_ancestors.csv` file identifies groups of notebooks derived from a common origin, that is, notebooks belonging to the same forking tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001756c60be8</th>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00015c83e2717b</th>\n",
       "      <td>aa2da37e</td>\n",
       "      <td>317b65d12af9df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001bdd4021779</th>\n",
       "      <td>a7711fde</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001daf4c2c76d</th>\n",
       "      <td>090152ca</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002115f48f982</th>\n",
       "      <td>272b483a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffc30d5a0bc46</th>\n",
       "      <td>6aed207b</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffc3b44869198</th>\n",
       "      <td>a6aaa8d7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffc63ff750064</th>\n",
       "      <td>0a1b5b65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffcd063cda949</th>\n",
       "      <td>d971e960</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffe1d764579d5</th>\n",
       "      <td>3c40bfa6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139256 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ancestor_id       parent_id\n",
       "id                                        \n",
       "00001756c60be8    945aea18             NaN\n",
       "00015c83e2717b    aa2da37e  317b65d12af9df\n",
       "0001bdd4021779    a7711fde             NaN\n",
       "0001daf4c2c76d    090152ca             NaN\n",
       "0002115f48f982    272b483a             NaN\n",
       "...                    ...             ...\n",
       "fffc30d5a0bc46    6aed207b             NaN\n",
       "fffc3b44869198    a6aaa8d7             NaN\n",
       "fffc63ff750064    0a1b5b65             NaN\n",
       "fffcd063cda949    d971e960             NaN\n",
       "fffe1d764579d5    3c40bfa6             NaN\n",
       "\n",
       "[139256 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ancestors = pd.read_csv(data_dir / 'train_ancestors.csv', index_col='id')\n",
    "df_ancestors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent leakage, the test set has no notebook with an ancestor in the training set. We therefore form a validation split using `ancestor_id` as a grouping factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#KL - here, we want to make sure our training set and validation set DO NOT have data leakeage.\n",
    "#this is an issue because many notebooks are from the same fork.  IF we include notebooks from the same fork in training\n",
    "#and validation, any alogirithim may simply decide to memorize the commonalities to predict, which we want to avoid.\n",
    "\n",
    "#Therefore, when we split the notebooks into training and validation, we want to make sure ALL of a fork goes into only \n",
    "#validation, OR training.  To do this, we use group shuffle split, and feed in the information from the 'ancestors'\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "NVALID = 0.1  # size of validation set\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=NVALID, random_state=0)\n",
    "\n",
    "# Split, keeping notebooks with a common origin (ancestor_id) together\n",
    "ids = df.index.unique('id')\n",
    "ancestors = df_ancestors.loc[ids, 'ancestor_id']\n",
    "ids_train, ids_valid = next(splitter.split(ids, groups=ancestors))\n",
    "ids_train, ids_valid = ids[ids_train], ids[ids_valid]\n",
    "\n",
    "df_train = df.loc[ids_train, :]\n",
    "df_valid = df.loc[ids_valid, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering #\n",
    "\n",
    "Let's generate [tf-idf features](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer) to use with our ranking model. These features will help our model learn what kinds of words tend to occur most often at various positions within a notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Training set\n",
    "tfidf = TfidfVectorizer(min_df=0.01)\n",
    "X_train = tfidf.fit_transform(df_train['source'].astype(str))\n",
    "# Rank of each cell within the notebook\n",
    "y_train = df_ranks.loc[ids_train].to_numpy()\n",
    "# Number of cells in each notebook\n",
    "groups = df_ranks.loc[ids_train].groupby('id').size().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416743, 280)\n",
      "  (0, 162)\t0.045459803822181045\n",
      "  (0, 35)\t0.06738644517234817\n",
      "  (0, 234)\t0.0873809155041615\n",
      "  (0, 38)\t0.07890611225025879\n",
      "  (0, 16)\t0.08053085489967879\n",
      "  (0, 254)\t0.07368027830383203\n",
      "  (0, 54)\t0.07884171815489997\n",
      "  (0, 263)\t0.08585969572872988\n",
      "  (0, 171)\t0.08355245628758512\n",
      "  (0, 228)\t0.06197821898023017\n",
      "  (0, 250)\t0.08904813742242577\n",
      "  (0, 40)\t0.13213356082602562\n",
      "  (0, 278)\t0.22268566155583808\n",
      "  (0, 119)\t0.08246795502416421\n",
      "  (0, 174)\t0.08193964232301745\n",
      "  (0, 183)\t0.05345768806988965\n",
      "  (0, 167)\t0.23350814043737944\n",
      "  (0, 15)\t0.14022887907750722\n",
      "  (0, 133)\t0.07429332663299502\n",
      "  (0, 267)\t0.06841562311142822\n",
      "  (0, 166)\t0.07112099202943088\n",
      "  (0, 199)\t0.17823644861549026\n",
      "  (0, 165)\t0.08009917775638646\n",
      "  (0, 190)\t0.09086365271147324\n",
      "  (0, 109)\t0.13288019028200737\n",
      "  :\t:\n",
      "  (416654, 279)\t33.0\n",
      "  (416655, 279)\t34.0\n",
      "  (416656, 279)\t35.0\n",
      "  (416657, 279)\t36.0\n",
      "  (416658, 279)\t37.0\n",
      "  (416659, 279)\t38.0\n",
      "  (416660, 279)\t39.0\n",
      "  (416661, 279)\t40.0\n",
      "  (416662, 279)\t41.0\n",
      "  (416663, 279)\t42.0\n",
      "  (416664, 279)\t43.0\n",
      "  (416665, 279)\t44.0\n",
      "  (416717, 279)\t1.0\n",
      "  (416718, 279)\t2.0\n",
      "  (416719, 279)\t3.0\n",
      "  (416720, 279)\t4.0\n",
      "  (416721, 279)\t5.0\n",
      "  (416722, 279)\t6.0\n",
      "  (416723, 279)\t7.0\n",
      "  (416724, 279)\t8.0\n",
      "  (416725, 279)\t9.0\n",
      "  (416726, 279)\t10.0\n",
      "  (416727, 279)\t11.0\n",
      "  (416728, 279)\t12.0\n",
      "  (416729, 279)\t13.0\n"
     ]
    }
   ],
   "source": [
    "#KL I added this codeblock to help illustrate the results of TF-IDF\n",
    "\n",
    "#(0, 162)The 0 refers to the document number, the 162 refers to the word.  The 0.0454 refers to the\n",
    "#inverse frequency of that word.  This is the feature vector that we will use.\n",
    "#note that with min_df - 0.01 it discards all words that are not in at least 1% of all documents.\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the code cell ordering as a feature. We'll append a column that enumerates the code cells in the correct order, like `1, 2, 3, 4, ...`, while having the dummy value `0` for all markdown cells. This feature will help the model learn to put the code cells in the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416743, 280)\n"
     ]
    }
   ],
   "source": [
    "# Add code cell ordering\n",
    "X_train = sparse.hstack((\n",
    "    X_train,\n",
    "    np.where(\n",
    "        df_train['cell_type'] == 'code',\n",
    "        df_train.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n",
    "        0,\n",
    "    ).reshape(-1, 1)\n",
    "))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the ranking algorithm provided by XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRanker(base_score=0.5, booster='gbtree', callbacks=None, colsample_bylevel=1,\n",
       "          colsample_bynode=1, colsample_bytree=1, early_stopping_rounds=None,\n",
       "          enable_categorical=False, eval_metric=None, gamma=0, gpu_id=-1,\n",
       "          grow_policy='depthwise', importance_type=None,\n",
       "          interaction_constraints='', learning_rate=0.300000012, max_bin=256,\n",
       "          max_cat_to_onehot=4, max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "          min_child_weight=10, missing=nan, monotone_constraints='()',\n",
       "          n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "          objective='rank:pairwise', predictor='auto', random_state=0,\n",
       "          reg_alpha=0, ...)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KL Create an XG ranker model and train it.\n",
    "\n",
    "from xgboost import XGBRanker\n",
    "\n",
    "model = XGBRanker(\n",
    "    min_child_weight=10,\n",
    "    subsample=0.5,\n",
    "    tree_method='hist',\n",
    ")\n",
    "model.fit(X_train, y_train, group=groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how well our model learned to order Kaggle notebook cells. We'll evaluate predictions on the validation set with a variant of the Kendall tau correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll create features for the validation set just like we did for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set\n",
    "X_valid = tfidf.transform(df_valid['source'].astype(str))\n",
    "# The metric uses cell ids\n",
    "y_valid = df_orders.loc[ids_valid]\n",
    "\n",
    "X_valid = sparse.hstack((\n",
    "    X_valid,\n",
    "    np.where(\n",
    "        df_valid['cell_type'] == 'code',\n",
    "        df_valid.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n",
    "        0,\n",
    "    ).reshape(-1, 1)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll use the model to predict the rank of each cell within its notebook and then convert these ranks into a list of ordered cell ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "000757b90aaca0    [8f84d7a9, 93cceeef, eb6ca769, 3cb3d383, bc595bc2, 1c301fa2, abc159f0, b20690ef, 6e3a3d90, a32974f3, 4e2b2854, 336fd...\n",
       "0015b3a7b1d090    [f9d1d049, 6b839e2c, d0bed918, f7f7add5, a3b5283b, 152bae08, 8b28582f, 37117c2f, 83592431, f66232c0, 91d77777, f9e7d...\n",
       "001f67f7a77619    [0b66280b, 7f81821a, 46329b3c, 7a1ee188, 8d996785, a1265d02, 118cd02c, 96b9c492, eb9aa0df, 34457700, 72934658, 95722...\n",
       "0020e93727e09c    [2ae0558f, c99eb39c, 0395ecde, 3de50426, f7501ae7, 660e2f96, a496bff8, 735a621c, c6ae803e, 4fbe373e, 82d91b5d, d3726...\n",
       "002132326fc1cd    [15bb3783, 37f42952, a935d196, 58c61e7c, f96000e2, 48d204ea, 6a3b489e, 8faaf8eb, 76c4ba1f, d3c00b4a, ffd91295, 1b033...\n",
       "0030ea6c6281ce    [b8ff09de, 532dd206, 6d1c9755, 1d0804d1, 0aa598c5, ca7507bb, c0bc83de, b0202ee4, 699baeea, c74e572f, 42586e3f, 338d3...\n",
       "003387e4d35cd9    [1871bc80, 9758b959, 8ef3c7b5, 4bfc51d6, bdfe4baa, f8b34ee9, eef4482a, 3c0e68ab, 5a2f4395, 936256c6, 9edac9dc, 6a7cd...\n",
       "0035bf6f9e264f    [1de4b0ca, 91a8a095, d3991c35, 3b6fee3a, c5bc02a6, c9c388c1, ee3d4d27, e44304f2, b8175ad3, ebb18de0, 6b45ced9, cb92d...\n",
       "00401bc0f47ed1    [f88724cf, 0887cba0, b3e68875, 9d87e5c8, b04c54ec, 16e1f068, 46189238, a0c17f96, 4520ba37, 1a269618, 242e9c42, d6eb5...\n",
       "0044804b2c920b    [2c1bc192, 93ffba7d, c6737c73, 0f4f1880, 3adc24b4, 59cc8d42, 128165da, 420097d2, fe09237d, f178c7b0, 11c824a3, 10ebd...\n",
       "Name: cell_id, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pd.DataFrame({'rank': model.predict(X_valid)}, index=df_valid.index)\n",
    "y_pred = (\n",
    "    y_pred\n",
    "    .sort_values(['id', 'rank'])  # Sort the cells in each notebook by their rank.\n",
    "                                  # The cell_ids are now in the order the model predicted.\n",
    "    .reset_index('cell_id')  # Convert the cell_id index into a column.\n",
    "    .groupby('id')['cell_id'].apply(list)  # Group the cell_ids for each notebook into a list.\n",
    ")\n",
    "y_pred.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's examine a notebook to see how the model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f88724cf</th>\n",
       "      <td>code</td>\n",
       "      <td>print(14 * \" &gt;\", \"\\t n.B.a. \\t\", \"&lt; \" * 14, \"\\n\\n\\n\")\\n\\n# This Python 3 environment comes with many helpful analyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0887cba0</th>\n",
       "      <td>code</td>\n",
       "      <td># Define dictionary\\ndictionary = {\"column1\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\\n              \"c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3e68875</th>\n",
       "      <td>code</td>\n",
       "      <td>data_missingno.head(10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9d87e5c8</th>\n",
       "      <td>code</td>\n",
       "      <td># import missingno library\\n\\nimport missingno as msno\\n\\nmsno.matrix(data_missingno)\\nplt.show()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16e1f068</th>\n",
       "      <td>code</td>\n",
       "      <td>msno.bar(data_missingno)\\nplt.show()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b04c54ec</th>\n",
       "      <td>code</td>\n",
       "      <td>data = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\\ndata.head()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46189238</th>\n",
       "      <td>code</td>\n",
       "      <td>data.rename(columns = {'fixed acidity': 'fixed_acidity', 'volatile acidity': 'volatile_acidity', 'citric acid': 'cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a0c17f96</th>\n",
       "      <td>code</td>\n",
       "      <td>data.info()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520ba37</th>\n",
       "      <td>code</td>\n",
       "      <td># Make the plot\\nplt.figure(figsize=(15,10))\\nparallel_coordinates(data, 'quality', colormap=plt.get_cmap(\"Set1\"))\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242e9c42</th>\n",
       "      <td>code</td>\n",
       "      <td># Calculate the correlation between individuals.\\ncorr = data.iloc[:,0:10].corr()\\ncorr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1a269618</th>\n",
       "      <td>code</td>\n",
       "      <td># import networkx library\\nimport networkx as nx\\n\\n# Transform it in a links data frame (3 columns only):\\nlinks = ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8e73cae6</th>\n",
       "      <td>code</td>\n",
       "      <td># correlation\\nthreshold = -1           # Simdi bu esik degerine gore aradaki bagi gosteren bir grafik cizelim\\n\\n# ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d6eb5c5c</th>\n",
       "      <td>code</td>\n",
       "      <td>data.head()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2c6e3ad4</th>\n",
       "      <td>code</td>\n",
       "      <td># venn2\\nfrom matplotlib_venn import venn2\\npH = data.iloc[:,0]\\ncitric_acid = data.iloc[:,1]\\nresidual_sugar = data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f66aaf2c</th>\n",
       "      <td>code</td>\n",
       "      <td># donut plot\\nfeature_names = \"pH\",\"citric_acid\",\"residual_sugar\",\"density\"\\nfeature_size = [len(pH),len(citric_acid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139cf87</th>\n",
       "      <td>code</td>\n",
       "      <td># spider graph\\ncategories = list(data)[1:]\\nN = len(categories)\\nangles = [ n / float(N)*2*pi for n in range(N)]\\na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8b0a568</th>\n",
       "      <td>code</td>\n",
       "      <td># cluster map (dendogram and tree)\\n\\ndf = data.loc[:,[\"pH\",\"citric_acid\",\"residual_sugar\",\"density\"]]\\ndf1 = data.q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111d21a</th>\n",
       "      <td>code</td>\n",
       "      <td># trace1 is line plot\\n# go: graph object\\ntrace1 = go.Scatter(\\n    x=df.index,\\n    y=df.pH,\\n    mode = \"markers\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317a1d0b</th>\n",
       "      <td>code</td>\n",
       "      <td>\\nquality7 = data[data.quality == 7]\\n# # data of iris virginica\\nquality8 = data[data.quality == 8]\\n\\n# trace1 =  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2e781ba7</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Cluster Map (Seaborn)\\n\\n## Indicates which properties are linked to each other.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77aa2779</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Spider Chart (Matplotlib)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71c90e21</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## The Venn diagram shows us the link between them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df2bd5e4</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Parallel Plots (Pandas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85b08bae</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Venn (Matplotlib)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52701079</th>\n",
       "      <td>markdown</td>\n",
       "      <td>Let's look visually according to the dataframe we prepared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b6ee2cab</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## Missingno bar plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86347f8e</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Network Charts (Networkx)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f92d43c5</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## **The main purpose of this study is to create sample visualizations on a data set!**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398be2d3</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Inset Plots (Plotly)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72965daa</th>\n",
       "      <td>markdown</td>\n",
       "      <td>Donut (Matplotlib)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75212aff</th>\n",
       "      <td>markdown</td>\n",
       "      <td>Let's give random nan values to see NaN values</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0879b7bc</th>\n",
       "      <td>markdown</td>\n",
       "      <td>**These images can be improved and made more beautiful. If there are places that are not understood, you can ask!**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9a03987a</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Basic 3D Scatter Plot (Plotly)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_type                                                                                                                   source\n",
       "cell_id                                                                                                                                    \n",
       "f88724cf      code  print(14 * \" >\", \"\\t n.B.a. \\t\", \"< \" * 14, \"\\n\\n\\n\")\\n\\n# This Python 3 environment comes with many helpful analyti...\n",
       "0887cba0      code  # Define dictionary\\ndictionary = {\"column1\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\\n              \"c...\n",
       "b3e68875      code                                                                                                  data_missingno.head(10)\n",
       "9d87e5c8      code                        # import missingno library\\n\\nimport missingno as msno\\n\\nmsno.matrix(data_missingno)\\nplt.show()\n",
       "16e1f068      code                                                                                     msno.bar(data_missingno)\\nplt.show()\n",
       "b04c54ec      code                  data = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\\ndata.head()\n",
       "46189238      code  data.rename(columns = {'fixed acidity': 'fixed_acidity', 'volatile acidity': 'volatile_acidity', 'citric acid': 'cit...\n",
       "a0c17f96      code                                                                                                              data.info()\n",
       "4520ba37      code  # Make the plot\\nplt.figure(figsize=(15,10))\\nparallel_coordinates(data, 'quality', colormap=plt.get_cmap(\"Set1\"))\\n...\n",
       "242e9c42      code                                  # Calculate the correlation between individuals.\\ncorr = data.iloc[:,0:10].corr()\\ncorr\n",
       "1a269618      code  # import networkx library\\nimport networkx as nx\\n\\n# Transform it in a links data frame (3 columns only):\\nlinks = ...\n",
       "8e73cae6      code  # correlation\\nthreshold = -1           # Simdi bu esik degerine gore aradaki bagi gosteren bir grafik cizelim\\n\\n# ...\n",
       "d6eb5c5c      code                                                                                                              data.head()\n",
       "2c6e3ad4      code  # venn2\\nfrom matplotlib_venn import venn2\\npH = data.iloc[:,0]\\ncitric_acid = data.iloc[:,1]\\nresidual_sugar = data...\n",
       "f66aaf2c      code  # donut plot\\nfeature_names = \"pH\",\"citric_acid\",\"residual_sugar\",\"density\"\\nfeature_size = [len(pH),len(citric_acid...\n",
       "2139cf87      code  # spider graph\\ncategories = list(data)[1:]\\nN = len(categories)\\nangles = [ n / float(N)*2*pi for n in range(N)]\\na...\n",
       "f8b0a568      code  # cluster map (dendogram and tree)\\n\\ndf = data.loc[:,[\"pH\",\"citric_acid\",\"residual_sugar\",\"density\"]]\\ndf1 = data.q...\n",
       "1111d21a      code  # trace1 is line plot\\n# go: graph object\\ntrace1 = go.Scatter(\\n    x=df.index,\\n    y=df.pH,\\n    mode = \"markers\"...\n",
       "317a1d0b      code  \\nquality7 = data[data.quality == 7]\\n# # data of iris virginica\\nquality8 = data[data.quality == 8]\\n\\n# trace1 =  ...\n",
       "2e781ba7  markdown                                       # Cluster Map (Seaborn)\\n\\n## Indicates which properties are linked to each other.\n",
       "77aa2779  markdown                                                                                              # Spider Chart (Matplotlib)\n",
       "71c90e21  markdown                                                                      ## The Venn diagram shows us the link between them.\n",
       "df2bd5e4  markdown                                                                                                # Parallel Plots (Pandas)\n",
       "85b08bae  markdown                                                                                                      # Venn (Matplotlib)\n",
       "52701079  markdown                                                               Let's look visually according to the dataframe we prepared\n",
       "b6ee2cab  markdown                                                                                                    ## Missingno bar plot\n",
       "86347f8e  markdown                                                                                              # Network Charts (Networkx)\n",
       "f92d43c5  markdown                                  ## **The main purpose of this study is to create sample visualizations on a data set!**\n",
       "398be2d3  markdown                                                                                                   # Inset Plots (Plotly)\n",
       "72965daa  markdown                                                                                                       Donut (Matplotlib)\n",
       "75212aff  markdown                                                                           Let's give random nan values to see NaN values\n",
       "0879b7bc  markdown      **These images can be improved and made more beautiful. If there are places that are not understood, you can ask!**\n",
       "9a03987a  markdown                                                                                         # Basic 3D Scatter Plot (Plotly)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f88724cf</th>\n",
       "      <td>code</td>\n",
       "      <td>print(14 * \" &gt;\", \"\\t n.B.a. \\t\", \"&lt; \" * 14, \"\\n\\n\\n\")\\n\\n# This Python 3 environment comes with many helpful analyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0887cba0</th>\n",
       "      <td>code</td>\n",
       "      <td># Define dictionary\\ndictionary = {\"column1\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\\n              \"c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3e68875</th>\n",
       "      <td>code</td>\n",
       "      <td>data_missingno.head(10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9d87e5c8</th>\n",
       "      <td>code</td>\n",
       "      <td># import missingno library\\n\\nimport missingno as msno\\n\\nmsno.matrix(data_missingno)\\nplt.show()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b04c54ec</th>\n",
       "      <td>code</td>\n",
       "      <td>data = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\\ndata.head()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16e1f068</th>\n",
       "      <td>code</td>\n",
       "      <td>msno.bar(data_missingno)\\nplt.show()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46189238</th>\n",
       "      <td>code</td>\n",
       "      <td>data.rename(columns = {'fixed acidity': 'fixed_acidity', 'volatile acidity': 'volatile_acidity', 'citric acid': 'cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a0c17f96</th>\n",
       "      <td>code</td>\n",
       "      <td>data.info()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520ba37</th>\n",
       "      <td>code</td>\n",
       "      <td># Make the plot\\nplt.figure(figsize=(15,10))\\nparallel_coordinates(data, 'quality', colormap=plt.get_cmap(\"Set1\"))\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1a269618</th>\n",
       "      <td>code</td>\n",
       "      <td># import networkx library\\nimport networkx as nx\\n\\n# Transform it in a links data frame (3 columns only):\\nlinks = ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242e9c42</th>\n",
       "      <td>code</td>\n",
       "      <td># Calculate the correlation between individuals.\\ncorr = data.iloc[:,0:10].corr()\\ncorr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d6eb5c5c</th>\n",
       "      <td>code</td>\n",
       "      <td>data.head()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f92d43c5</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## **The main purpose of this study is to create sample visualizations on a data set!**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2c6e3ad4</th>\n",
       "      <td>code</td>\n",
       "      <td># venn2\\nfrom matplotlib_venn import venn2\\npH = data.iloc[:,0]\\ncitric_acid = data.iloc[:,1]\\nresidual_sugar = data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8e73cae6</th>\n",
       "      <td>code</td>\n",
       "      <td># correlation\\nthreshold = -1           # Simdi bu esik degerine gore aradaki bagi gosteren bir grafik cizelim\\n\\n# ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8b0a568</th>\n",
       "      <td>code</td>\n",
       "      <td># cluster map (dendogram and tree)\\n\\ndf = data.loc[:,[\"pH\",\"citric_acid\",\"residual_sugar\",\"density\"]]\\ndf1 = data.q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df2bd5e4</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Parallel Plots (Pandas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0879b7bc</th>\n",
       "      <td>markdown</td>\n",
       "      <td>**These images can be improved and made more beautiful. If there are places that are not understood, you can ask!**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139cf87</th>\n",
       "      <td>code</td>\n",
       "      <td># spider graph\\ncategories = list(data)[1:]\\nN = len(categories)\\nangles = [ n / float(N)*2*pi for n in range(N)]\\na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f66aaf2c</th>\n",
       "      <td>code</td>\n",
       "      <td># donut plot\\nfeature_names = \"pH\",\"citric_acid\",\"residual_sugar\",\"density\"\\nfeature_size = [len(pH),len(citric_acid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52701079</th>\n",
       "      <td>markdown</td>\n",
       "      <td>Let's look visually according to the dataframe we prepared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77aa2779</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Spider Chart (Matplotlib)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85b08bae</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Venn (Matplotlib)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72965daa</th>\n",
       "      <td>markdown</td>\n",
       "      <td>Donut (Matplotlib)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317a1d0b</th>\n",
       "      <td>code</td>\n",
       "      <td>\\nquality7 = data[data.quality == 7]\\n# # data of iris virginica\\nquality8 = data[data.quality == 8]\\n\\n# trace1 =  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111d21a</th>\n",
       "      <td>code</td>\n",
       "      <td># trace1 is line plot\\n# go: graph object\\ntrace1 = go.Scatter(\\n    x=df.index,\\n    y=df.pH,\\n    mode = \"markers\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71c90e21</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## The Venn diagram shows us the link between them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86347f8e</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Network Charts (Networkx)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398be2d3</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Inset Plots (Plotly)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2e781ba7</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Cluster Map (Seaborn)\\n\\n## Indicates which properties are linked to each other.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9a03987a</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Basic 3D Scatter Plot (Plotly)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b6ee2cab</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## Missingno bar plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75212aff</th>\n",
       "      <td>markdown</td>\n",
       "      <td>Let's give random nan values to see NaN values</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_type                                                                                                                   source\n",
       "cell_id                                                                                                                                    \n",
       "f88724cf      code  print(14 * \" >\", \"\\t n.B.a. \\t\", \"< \" * 14, \"\\n\\n\\n\")\\n\\n# This Python 3 environment comes with many helpful analyti...\n",
       "0887cba0      code  # Define dictionary\\ndictionary = {\"column1\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\\n              \"c...\n",
       "b3e68875      code                                                                                                  data_missingno.head(10)\n",
       "9d87e5c8      code                        # import missingno library\\n\\nimport missingno as msno\\n\\nmsno.matrix(data_missingno)\\nplt.show()\n",
       "b04c54ec      code                  data = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\\ndata.head()\n",
       "16e1f068      code                                                                                     msno.bar(data_missingno)\\nplt.show()\n",
       "46189238      code  data.rename(columns = {'fixed acidity': 'fixed_acidity', 'volatile acidity': 'volatile_acidity', 'citric acid': 'cit...\n",
       "a0c17f96      code                                                                                                              data.info()\n",
       "4520ba37      code  # Make the plot\\nplt.figure(figsize=(15,10))\\nparallel_coordinates(data, 'quality', colormap=plt.get_cmap(\"Set1\"))\\n...\n",
       "1a269618      code  # import networkx library\\nimport networkx as nx\\n\\n# Transform it in a links data frame (3 columns only):\\nlinks = ...\n",
       "242e9c42      code                                  # Calculate the correlation between individuals.\\ncorr = data.iloc[:,0:10].corr()\\ncorr\n",
       "d6eb5c5c      code                                                                                                              data.head()\n",
       "f92d43c5  markdown                                  ## **The main purpose of this study is to create sample visualizations on a data set!**\n",
       "2c6e3ad4      code  # venn2\\nfrom matplotlib_venn import venn2\\npH = data.iloc[:,0]\\ncitric_acid = data.iloc[:,1]\\nresidual_sugar = data...\n",
       "8e73cae6      code  # correlation\\nthreshold = -1           # Simdi bu esik degerine gore aradaki bagi gosteren bir grafik cizelim\\n\\n# ...\n",
       "f8b0a568      code  # cluster map (dendogram and tree)\\n\\ndf = data.loc[:,[\"pH\",\"citric_acid\",\"residual_sugar\",\"density\"]]\\ndf1 = data.q...\n",
       "df2bd5e4  markdown                                                                                                # Parallel Plots (Pandas)\n",
       "0879b7bc  markdown      **These images can be improved and made more beautiful. If there are places that are not understood, you can ask!**\n",
       "2139cf87      code  # spider graph\\ncategories = list(data)[1:]\\nN = len(categories)\\nangles = [ n / float(N)*2*pi for n in range(N)]\\na...\n",
       "f66aaf2c      code  # donut plot\\nfeature_names = \"pH\",\"citric_acid\",\"residual_sugar\",\"density\"\\nfeature_size = [len(pH),len(citric_acid...\n",
       "52701079  markdown                                                               Let's look visually according to the dataframe we prepared\n",
       "77aa2779  markdown                                                                                              # Spider Chart (Matplotlib)\n",
       "85b08bae  markdown                                                                                                      # Venn (Matplotlib)\n",
       "72965daa  markdown                                                                                                       Donut (Matplotlib)\n",
       "317a1d0b      code  \\nquality7 = data[data.quality == 7]\\n# # data of iris virginica\\nquality8 = data[data.quality == 8]\\n\\n# trace1 =  ...\n",
       "1111d21a      code  # trace1 is line plot\\n# go: graph object\\ntrace1 = go.Scatter(\\n    x=df.index,\\n    y=df.pH,\\n    mode = \"markers\"...\n",
       "71c90e21  markdown                                                                      ## The Venn diagram shows us the link between them.\n",
       "86347f8e  markdown                                                                                              # Network Charts (Networkx)\n",
       "398be2d3  markdown                                                                                                   # Inset Plots (Plotly)\n",
       "2e781ba7  markdown                                       # Cluster Map (Seaborn)\\n\\n## Indicates which properties are linked to each other.\n",
       "9a03987a  markdown                                                                                         # Basic 3D Scatter Plot (Plotly)\n",
       "b6ee2cab  markdown                                                                                                    ## Missingno bar plot\n",
       "75212aff  markdown                                                                           Let's give random nan values to see NaN values"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_id = df_valid.index.get_level_values('id').unique()[8]\n",
    "\n",
    "display(df.loc[nb_id])\n",
    "display(df.loc[nb_id].loc[y_pred.loc[nb_id]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric ##\n",
    "\n",
    "This competition uses a variant of the [Kendall tau correlation](https://www.kaggle.com/competitions/AI4Code/overview/evaluation), which will measure how close to the correct order our predicted orderings are. See this notebook for more on this metric: [Competition Metric - Kendall Tau Correlation](https://www.kaggle.com/code/ryanholbrook/competition-metric-kendall-tau-correlation/notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#KL Kendall Tau is basically a measure of how many times you have to swap 2 adjacaent cells to get the right order.\n",
    "#as such it penalizes predictions which are drastically off the correct number more than those which are only 1 or 2 off.\n",
    "#they implement their own custom method for this below\n",
    "\n",
    "from bisect import bisect\n",
    "\n",
    "\n",
    "def count_inversions(a):\n",
    "    inversions = 0\n",
    "    sorted_so_far = []\n",
    "    for i, u in enumerate(a):\n",
    "        j = bisect(sorted_so_far, u)\n",
    "        inversions += i - j\n",
    "        sorted_so_far.insert(j, u)\n",
    "    return inversions\n",
    "\n",
    "\n",
    "def kendall_tau(ground_truth, predictions):\n",
    "    total_inversions = 0\n",
    "    total_2max = 0  # twice the maximum possible inversions across all instances\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n",
    "        total_inversions += count_inversions(ranks)\n",
    "        n = len(gt)\n",
    "        total_2max += n * (n - 1)\n",
    "    return 1 - 4 * total_inversions / total_2max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the metric with a dummy submission created from the ids of the shuffled notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37616093940244355"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dummy = df_valid.reset_index('cell_id').groupby('id')['cell_id'].apply(list)\n",
    "kendall_tau(y_valid, y_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing this to the score on the predictions, we can see that our model was indeed able to improve the cell ordering somewhat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.585791847404556"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendall_tau(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a submission for this competition, we'll apply our model to the notebooks in the test set. Note that this is a **Code Competition**, which means that the test data we see here is only a small sample. When we submit our notebook for scoring, this example data will be replaced with the full test set of about 20,000 notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test NBs: 100%|██████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 78.64it/s]\n"
     ]
    }
   ],
   "source": [
    "paths_test = list((data_dir / 'test').glob('*.json'))\n",
    "notebooks_test = [\n",
    "    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n",
    "]\n",
    "df_test = (\n",
    "    pd.concat(notebooks_test)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create the tf-idf and code cell features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_test = tfidf.transform(df_test['source'].astype(str))\n",
    "X_test = sparse.hstack((\n",
    "    X_test,\n",
    "    np.where(\n",
    "        df_test['cell_type'] == 'code',\n",
    "        df_test.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n",
    "        0,\n",
    "    ).reshape(-1, 1)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then create predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0009d135ece78d    [ddfd239c, c6cd22db, 1372ae9b, 7f388a41, 90ed07ab, 8cb8d28a, f9893819, 2843a25a, 06dbf8cf, 0a226b6a, 39e937ec, ba55e...\n",
       "0010483c12ba9b                       [54c7cab3, fe66203e, 7844d5f8, 5ce8863c, 7f270e34, 4a32c095, 02a0be6d, 865ad516, 4a0777c4, 4703bb6d]\n",
       "0010a919d60e4f    [aafc3d23, b7578789, 80e077ec, b190ebb4, ed415c3c, 322850af, 8ce62db4, 5115ebe5, 868c4eae, 4ae17669, 23607d04, 80433...\n",
       "0028856e09c5b7                                                                                   [012c9d02, d22526d1, 3ae7ece3, eb293dfc]\n",
       "Name: cell_id, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_infer = pd.DataFrame({'rank': model.predict(X_test)}, index=df_test.index)\n",
    "y_infer = y_infer.sort_values(['id', 'rank']).reset_index('cell_id').groupby('id')['cell_id'].apply(list)\n",
    "y_infer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sample_submission.csv` file shows what a correctly formatted submission must look like. We'll just use it as a visual check, but you might like to directly modify the values of sample submission instead. (This would help prevent failed submissions due to missing notebook ids or incorrectly named columns, for instance.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0009d135ece78d       ddfd239c c6cd22db 1372ae9b 90ed07ab 7f388a41 2843a25a 06dbf8cf f9893819 ba55e576 39e937ec e25aa9bd 0a226b6a 8cb8d28a\n",
       "0010483c12ba9b                                  54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d 7f270e34\n",
       "0010a919d60e4f    aafc3d23 80e077ec b190ebb4 ed415c3c 322850af c069ed33 868c4eae 80433cf3 bd8fbd76 0e2529e8 1345b8b2 cdae286f 4907b9ef...\n",
       "0028856e09c5b7                                                                                        012c9d02 d22526d1 3ae7ece3 eb293dfc\n",
       "Name: cell_order, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample = pd.read_csv(data_dir / 'sample_submission.csv', index_col='id', squeeze=True)\n",
    "y_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a correctly formatted submission needs the index named `id` and the column of cell orders named `cell_order`. Moreover, we need to convert the list of cell ids into a space-delimited string of cell ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0009d135ece78d       ddfd239c c6cd22db 1372ae9b 7f388a41 90ed07ab 8cb8d28a f9893819 2843a25a 06dbf8cf 0a226b6a 39e937ec ba55e576 e25aa9bd\n",
       "0010483c12ba9b                                  54c7cab3 fe66203e 7844d5f8 5ce8863c 7f270e34 4a32c095 02a0be6d 865ad516 4a0777c4 4703bb6d\n",
       "0010a919d60e4f    aafc3d23 b7578789 80e077ec b190ebb4 ed415c3c 322850af 8ce62db4 5115ebe5 868c4eae 4ae17669 23607d04 80433cf3 c069ed33...\n",
       "0028856e09c5b7                                                                                        012c9d02 d22526d1 3ae7ece3 eb293dfc\n",
       "Name: cell_order, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_submit = (\n",
    "    y_infer\n",
    "    .apply(' '.join)  # list of ids -> string of ids\n",
    "    .rename_axis('id')\n",
    "    .rename('cell_order')\n",
    ")\n",
    "y_submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we'll write out the formatted submissions to a file `submission.csv`. When we submit our notebook, it will be rerun on the full test data to create the submission file that's actually scored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
